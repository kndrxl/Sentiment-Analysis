{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/sentiment_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "tokenizer_config.json: 100%|██████████| 338/338 [00:00<00:00, 692kB/s]\n",
      "vocab.txt: 100%|██████████| 843k/843k [00:00<00:00, 12.1MB/s]\n",
      "bpe.codes: 100%|██████████| 1.08M/1.08M [00:00<00:00, 10.9MB/s]\n",
      "added_tokens.json: 100%|██████████| 22.0/22.0 [00:00<00:00, 67.7kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 167/167 [00:00<00:00, 386kB/s]\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "config.json: 100%|██████████| 949/949 [00:00<00:00, 2.65MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 540M/540M [00:48<00:00, 11.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm \n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "MODEL_PATH = f\"../models/{MODEL_NAME}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "model.save_pretrained(MODEL_PATH)\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     MODEL_PATH,\n",
    "#     local_files_only=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        # t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        # t = 'http' if t.startswith('http') else t\n",
    "        t = '' if t.startswith(('@', 'http')) and len(t) > 1 else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def infer(text):\n",
    "    labels = ['negative', 'neutral', 'positive']\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "\n",
    "    output = ranking[0]\n",
    "    label = labels[output]\n",
    "    return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, true_labels):\n",
    "    cls_report = classification_report(\n",
    "        true_labels, \n",
    "        predictions\n",
    "    )\n",
    "    cnf_matrix = confusion_matrix(\n",
    "        true_labels, \n",
    "        predictions\n",
    "    )\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    print(\"Classification Report:\\n\", cls_report)\n",
    "    print(\"Confusion Matrix:\\n\", cnf_matrix)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "\n",
    "def test_batch(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    data = df['text'].tolist()\n",
    "    true_labels = df['expected_sentiment'].tolist()\n",
    "    predictions = []\n",
    "\n",
    "    for i in tqdm(range(len(data)), desc=\"Processing\"):\n",
    "        text = data[i]\n",
    "        true_label = true_labels[i]\n",
    "        processed_text, predicted_label = infer(text)\n",
    "        predictions.append(predicted_label)\n",
    "\n",
    "    evaluate(predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 498/498 [00:20<00:00, 24.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       177\n",
      "     neutral       0.84      0.80      0.82       139\n",
      "    positive       0.83      0.92      0.87       182\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.87      0.86      0.86       498\n",
      "weighted avg       0.87      0.87      0.87       498\n",
      "\n",
      "Confusion Matrix:\n",
      " [[153  11  13]\n",
      " [  8 111  20]\n",
      " [  5  10 167]]\n",
      "Accuracy:  0.8654618473895582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = '../data/sentiment_test_cases.csv'\n",
    "test_batch(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
